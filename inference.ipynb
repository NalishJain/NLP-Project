{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qFo4btZZ6Un",
        "outputId": "07da10a1-4647-44de-b2a2-bdcfd5e0d113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==2.14.6 in ./.venv/lib/python3.10/site-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (16.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (4.66.2)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.22.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets==2.14.6) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (4.0.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.16.0)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.39.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: evaluate in ./.venv/lib/python3.10/site-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in ./.venv/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (0.22.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: responses<0.19 in ./.venv/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.0.0)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.39.3)\n",
            "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: accelerate in ./.venv/lib/python3.10/site-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
            "Requirement already satisfied: huggingface-hub in ./.venv/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
            "Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "Successfully installed protobuf-5.26.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets==2.14.6\n",
        "# !pip install transformers\n",
        "# !pip install evaluate\n",
        "# !pip install --no-cache-dir transformers sentencepiece\n",
        "# !pip install accelerate -U\n",
        "!pip install protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nZivLybaZ-gV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nalishjain/Acad Sem 6/NLP-Project/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from dataclasses import dataclass\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_scheduler, TrainingArguments, Trainer\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import evaluate\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import accelerate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "czFjm3I4aCYd"
      },
      "outputs": [],
      "source": [
        "train_data = np.load('./data/SP-train.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_lists(data):\n",
        "    questions = []\n",
        "    choices = []\n",
        "    labels = []\n",
        "    for example in data:\n",
        "        # print(example.keys())\n",
        "        questions.append(example['question'])\n",
        "        choices.append(example['choice_list'])\n",
        "        labels.append(example['label'])\n",
        "    return questions, choices, labels\n",
        "\n",
        "class SentenceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SentenceModel, self).__init__()\n",
        "        self.fc_1 = nn.Linear(768, 256)\n",
        "        self.bn_1 = nn.BatchNorm1d(256)  \n",
        "        self.dropout_1 = nn.Dropout(0.2)  \n",
        "        self.fc_2 = nn.Linear(256, 32)\n",
        "        self.bn_2 = nn.BatchNorm1d(32)  \n",
        "        self.dropout_2 = nn.Dropout(0.3)  \n",
        "        self.fc_3 = nn.Linear(32, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc_1(x)\n",
        "        out = self.bn_1(out)  \n",
        "        out = nn.functional.relu(out)  \n",
        "        out = self.dropout_1(out)  \n",
        "        out = self.fc_2(out)\n",
        "        out = self.bn_2(out)  \n",
        "        out = nn.functional.relu(out)  \n",
        "        out = self.dropout_2(out) \n",
        "        out = self.fc_3(out)\n",
        "        return out\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru_1 = nn.GRU(768, 256, num_layers=1,batch_first=True)\n",
        "        self.gru_2 = nn.GRU(256, 64, num_layers=1,batch_first=True)\n",
        "        self.fc_1 = nn.Linear(64, 16)\n",
        "        self.fc_2 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru_1(x)  \n",
        "        out, _ = self.gru_2(out)              \n",
        "        out = self.fc_1(out[:, -1, :])\n",
        "        out = self.fc_2(out)\n",
        "        return out\n",
        "    \n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn_1 = nn.RNN(768, 256, num_layers=1,batch_first=True)\n",
        "        self.rnn_2 = nn.RNN(256, 64, num_layers=1,batch_first=True)\n",
        "        self.fc_1 = nn.Linear(64, 16)\n",
        "        self.fc_2 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn_1(x)  \n",
        "        out, _ = self.rnn_2(out)              \n",
        "        out = self.fc_1(out[:, -1, :])\n",
        "        # out = nn.functional.relu(out)  \n",
        "        out = self.fc_2(out)\n",
        "        return out\n",
        "    \n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm_1 = nn.LSTM(768, 256, num_layers=1,batch_first=True)\n",
        "        self.lstm_2 = nn.LSTM(256, 64, num_layers=1,batch_first=True)\n",
        "        self.fc_1 = nn.Linear(64, 16)\n",
        "        self.fc_2 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm_1(x)  \n",
        "        out, _ = self.lstm_2(out)              \n",
        "        out = self.fc_1(out[:, -1, :])\n",
        "        # out = nn.functional.relu(out)  \n",
        "        out = self.fc_2(out)\n",
        "        return out\n",
        "\n",
        "class Brain_Teaser(Dataset):\n",
        "  def __init__(self, obj):\n",
        "    self.questions = obj[0]\n",
        "    self.choices = obj[1]\n",
        "    self.labels = obj[2]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.questions)\n",
        "  \n",
        "  def __getitem__(self, id):\n",
        "    return self.questions[id], self.choices[id], self.labels[id]  \n",
        "  \n",
        "class Brain_Teaser_2(Dataset):\n",
        "  def __init__(self, tokenizer, questions, choices, labels, max_len=512):\n",
        "    self.questions = questions\n",
        "    self.choices = choices\n",
        "    self.labels = labels\n",
        "\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "    self.question_options_encoded = []\n",
        "\n",
        "    self.build_questions()\n",
        "  \n",
        "  def build_questions(self):\n",
        "    maxi = 0\n",
        "    for id in range(len(self.questions)):\n",
        "      qo = []\n",
        "      for option_id in range(4):\n",
        "        question_options = \"Question : \" + self.questions[id] + ' ' + \"Option: \" + str(option_id) + ' ' + self.choices[id][option_id] \n",
        "        qo.append(self.tokenizer.encode(question_options, convert_to_tensor = True))\n",
        "      self.question_options_encoded.append(qo)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.question_options_encoded)\n",
        "  \n",
        "  def __getitem__(self, id):\n",
        "    return torch.stack(self.question_options_encoded[id]),  self.labels[id]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4t_BdYEY9Qvr"
      },
      "outputs": [],
      "source": [
        "data = np.load(\"data/SP-train.npy\", allow_pickle=True)\n",
        "\n",
        "o_data = []\n",
        "sr_data = []\n",
        "cr_data = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    size_ = len(data[i]['id'])\n",
        "\n",
        "    if data[i]['id'][size_-2:size_] == 'CR':\n",
        "        cr_data.append(data[i])\n",
        "    elif data[i]['id'][size_-2:size_] == 'SR':\n",
        "        sr_data.append(data[i])\n",
        "    else:\n",
        "        o_data.append(data[i])\n",
        "model_name=\"bert-large-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train_data = o_data[:int(len(o_data)*0.8)] + cr_data[:int(len(cr_data)*0.8)] + sr_data[:int(len(sr_data)*0.8)]\n",
        "val_data = o_data[int(len(o_data)*0.8):int(len(o_data)*0.9)] + cr_data[int(len(cr_data)*0.8):int(len(cr_data)*0.9)] + sr_data[int(len(sr_data)*0.8):int(len(sr_data)*0.9)]\n",
        "test_data = o_data[int(len(o_data)*0.9):] + cr_data[int(len(cr_data)*0.9):] + sr_data[int(len(sr_data)*0.9):]\n",
        "\n",
        "o_test_data = o_data[int(len(o_data)*0.9):]\n",
        "c_test_data = cr_data[int(len(cr_data)*0.9):] \n",
        "s_test_data =  sr_data[int(len(sr_data)*0.9):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y5uPu6jXk9a0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'embedding_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m val_questions, val_choices, val_labels \u001b[38;5;241m=\u001b[39m get_data_lists(val_data)\n\u001b[1;32m     12\u001b[0m test_questions, test_choices, test_labels \u001b[38;5;241m=\u001b[39m get_data_lists(test_data)\n\u001b[0;32m---> 14\u001b[0m train_dataset_2 \u001b[38;5;241m=\u001b[39m Brain_Teaser_2(\u001b[43membedding_model\u001b[49m, train_questions, train_choices, train_labels)\n\u001b[1;32m     15\u001b[0m val_dataset_2 \u001b[38;5;241m=\u001b[39m Brain_Teaser_2(embedding_model, val_questions, val_choices, val_labels)\n\u001b[1;32m     16\u001b[0m test_dataset_2 \u001b[38;5;241m=\u001b[39m Brain_Teaser_2(embedding_model, test_questions, test_choices, test_labels)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "o_test_dataset = Brain_Teaser(get_data_lists(o_test_data))\n",
        "c_test_dataset = Brain_Teaser(get_data_lists(c_test_data))\n",
        "s_test_dataset = Brain_Teaser(get_data_lists(s_test_data))\n",
        "\n",
        "train_data = o_data[:int(len(o_data)*0.8)] + cr_data[:int(len(cr_data)*0.8)] + sr_data[:int(len(sr_data)*0.8)]\n",
        "val_data = o_data[int(len(o_data)*0.8):int(len(o_data)*0.9)] + cr_data[int(len(cr_data)*0.8):int(len(cr_data)*0.9)] + sr_data[int(len(sr_data)*0.8):int(len(sr_data)*0.9)]\n",
        "test_data = o_data[int(len(o_data)*0.9):] + cr_data[int(len(cr_data)*0.9):] + sr_data[int(len(sr_data)*0.9):]\n",
        "\n",
        "\n",
        "train_questions, train_choices, train_labels = get_data_lists(train_data)\n",
        "val_questions, val_choices, val_labels = get_data_lists(val_data)\n",
        "test_questions, test_choices, test_labels = get_data_lists(test_data)\n",
        "\n",
        "train_dataset_2 = Brain_Teaser_2(embedding_model, train_questions, train_choices, train_labels)\n",
        "val_dataset_2 = Brain_Teaser_2(embedding_model, val_questions, val_choices, val_labels)\n",
        "test_dataset_2 = Brain_Teaser_2(embedding_model, test_questions, test_choices, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.6462, -0.2440,  0.2941,  ..., -0.0312,  0.3269, -0.2828],\n",
              "         [-0.4100, -0.1910,  0.3373,  ...,  0.0210,  0.3945, -0.5179],\n",
              "         [-0.4757, -0.2962,  0.3105,  ...,  0.0132,  0.3523, -0.6067],\n",
              "         [-0.3288, -0.3289,  0.4456,  ..., -0.0748,  0.2734, -0.7899]],\n",
              "        device='mps:0'),\n",
              " 3)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset_2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1jPSaVR6aNET"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentence Transfomers + Sequential Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(test_dataset, model, batch = 1):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    # test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        for id in range(len(test_dataset)):\n",
        "            inputs = test_dataset[id][0].view(1,4,768)\n",
        "            targets = test_dataset[id][1]\n",
        "            inputs = inputs.to(device)\n",
        "            # targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += 1\n",
        "            # print(predicted[0], targets)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    print(f\"Test Accuracy: {(100 * correct / total):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN\n",
            "Test Accuracy: 47.06%\n",
            "LSTM\n",
            "Test Accuracy: 31.37%\n",
            "GRU\n",
            "Test Accuracy: 27.45%\n"
          ]
        }
      ],
      "source": [
        "print(\"RNN\")\n",
        "model_sentence_rnn = RNNModel()\n",
        "model_sentence_rnn.load_state_dict(torch.load('trained_models/sb_rnn.pt'))\n",
        "test_model(test_dataset_2, model_sentence_rnn)\n",
        "\n",
        "print(\"LSTM\")\n",
        "model_sentence_lstm = LSTMModel()\n",
        "model_sentence_lstm.load_state_dict(torch.load('trained_models/sb_lstm.pt'))\n",
        "test_model(test_dataset_2, model_sentence_lstm)\n",
        "\n",
        "print(\"GRU\")\n",
        "model_sentence_gru = GRUModel()\n",
        "model_sentence_gru.load_state_dict(torch.load('trained_models/sb_gru.pt'))\n",
        "test_model(test_dataset_2, model_sentence_gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Encoder Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nalishjain/Acad Sem 6/NLP-Project/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name=\"microsoft/deberta-v3-base\"\n",
        "tokenizer_deberta = AutoTokenizer.from_pretrained(model_name)\n",
        "model_deberta = AutoModelForMultipleChoice.from_pretrained(\"trained_models/deberta_model\", ignore_mismatched_sizes=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name= \"microsoft/deberta-v3-base\"\n",
        "tokenizer_deberta_ft = AutoTokenizer.from_pretrained(model_name)\n",
        "model_deberta_ft = AutoModelForMultipleChoice.from_pretrained(\"trained_models/deberta_ft_model\", ignore_mismatched_sizes=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name=\"FacebookAI/roberta-large\"\n",
        "tokenizer_roberta = AutoTokenizer.from_pretrained(model_name)\n",
        "model_roberta = AutoModelForMultipleChoice.from_pretrained(\"trained_models/roberta_model\", ignore_mismatched_sizes=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name=\"DeepPavlov/roberta-large-winogrande\"\n",
        "tokenizer_roberta_w = AutoTokenizer.from_pretrained(model_name)\n",
        "model_roberta_w = AutoModelForMultipleChoice.from_pretrained(\"trained_models/roberta_wngrd_model\", ignore_mismatched_sizes=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uhKq_j7saYI5"
      },
      "outputs": [],
      "source": [
        "def get_predictions(dataset, model, tokenizer):\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    for id in range(len(dataset)):\n",
        "        ques = dataset[id][0]\n",
        "        choices =  dataset[id][1]\n",
        "        true_label =  dataset[id][2]\n",
        "\n",
        "        inputs = tokenizer([[ques, choices[0]], [ques, choices[1]], [ques, choices[2]], [ques, choices[3]]], return_tensors = \"pt\", padding = True).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**{key: value.unsqueeze(0) for key, value in inputs.items()})\n",
        "        logits = outputs.logits\n",
        "        predicted_class = logits.argmax().item()\n",
        "        predictions.append(predicted_class)\n",
        "        targets.append(true_label)\n",
        "    \n",
        "    return predictions, targets\n",
        "\n",
        "def ensemble_predictions(predictions):\n",
        "    num_samples = len(predictions[0])\n",
        "    ensemble_pred = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        counts = Counter([pred[i] for pred in predictions])\n",
        "        majority_vote = counts.most_common(1)[0][0]\n",
        "        ensemble_pred.append(majority_vote)\n",
        "\n",
        "    return ensemble_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original Puzzles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1do2YeYAQ4FY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deberta \n",
            "0.7647058823529411\n",
            "Deberta FT\n",
            "0.8235294117647058\n",
            "Roberta\n",
            "0.7647058823529411\n",
            "Roberta Winogrande\n",
            "0.8235294117647058\n"
          ]
        }
      ],
      "source": [
        "deberta_prediction_o, target_o = get_predictions(o_test_dataset, model_deberta, tokenizer_deberta)\n",
        "print(\"Deberta \")\n",
        "print(accuracy_score(target_o, deberta_prediction_o ))\n",
        "\n",
        "deberta_ft_prediction_o, target_o = get_predictions(o_test_dataset, model_deberta_ft, tokenizer_deberta_ft)\n",
        "print(\"Deberta FT\")\n",
        "print(accuracy_score(target_o, deberta_ft_prediction_o ))\n",
        "\n",
        "roberta_prediction_o, target_o = get_predictions(o_test_dataset, model_roberta, tokenizer_roberta)\n",
        "print(\"Roberta\")\n",
        "print(accuracy_score(target_o, roberta_prediction_o))\n",
        "\n",
        "roberta_w_prediction_o, target_o = get_predictions(o_test_dataset, model_roberta_w, tokenizer_roberta_w)\n",
        "print(\"Roberta Winogrande\")\n",
        "print(accuracy_score(target_o, roberta_w_prediction_o ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Semantically Reconstructed Puzzles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deberta \n",
            "0.7647058823529411\n",
            "Deberta FT\n",
            "0.8235294117647058\n",
            "Roberta\n",
            "0.7647058823529411\n",
            "Roberta Winogrande\n",
            "0.8235294117647058\n"
          ]
        }
      ],
      "source": [
        "deberta_prediction_s, target_s = get_predictions(s_test_dataset, model_deberta, tokenizer_deberta)\n",
        "print(\"Deberta \")\n",
        "print(accuracy_score(target_s, deberta_prediction_s ))\n",
        "\n",
        "deberta_ft_prediction_s, target_s = get_predictions(s_test_dataset, model_deberta_ft, tokenizer_deberta_ft)\n",
        "print(\"Deberta FT\")\n",
        "print(accuracy_score(target_s, deberta_ft_prediction_s ))\n",
        "\n",
        "roberta_prediction_s, target_s = get_predictions(s_test_dataset, model_roberta, tokenizer_roberta)\n",
        "print(\"Roberta\")\n",
        "print(accuracy_score(target_s, roberta_prediction_s))\n",
        "\n",
        "roberta_w_prediction_s, target_s = get_predictions(s_test_dataset, model_roberta_w, tokenizer_roberta_w)\n",
        "print(\"Roberta Winogrande\")\n",
        "print(accuracy_score(target_s, roberta_w_prediction_s ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contextually Reconstructed Puzzles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deberta \n",
            "0.7058823529411765\n",
            "Deberta FT\n",
            "0.8235294117647058\n",
            "Roberta\n",
            "0.5882352941176471\n",
            "Roberta Winogrande\n",
            "0.7058823529411765\n"
          ]
        }
      ],
      "source": [
        "\n",
        "deberta_prediction_c, target_c = get_predictions(c_test_dataset, model_deberta, tokenizer_deberta)\n",
        "print(\"Deberta \")\n",
        "print(accuracy_score(target_c, deberta_prediction_c ))\n",
        "\n",
        "deberta_ft_prediction_c, target_c = get_predictions(c_test_dataset, model_deberta_ft, tokenizer_deberta_ft)\n",
        "print(\"Deberta FT\")\n",
        "print(accuracy_score(target_c, deberta_ft_prediction_c ))\n",
        "\n",
        "roberta_prediction_c, target_c = get_predictions(c_test_dataset, model_roberta, tokenizer_roberta)\n",
        "print(\"Roberta\")\n",
        "print(accuracy_score(target_c, roberta_prediction_c))\n",
        "\n",
        "roberta_w_prediction_c, target_c = get_predictions(c_test_dataset, model_roberta_w, tokenizer_roberta_w)\n",
        "print(\"Roberta Winogrande\")\n",
        "print(accuracy_score(target_c, roberta_w_prediction_c ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deberta \n",
            "0.7450980392156863\n",
            "Deberta FT\n",
            "0.8235294117647058\n",
            "Roberta\n",
            "0.7058823529411765\n",
            "Roberta Winogrande\n",
            "0.7843137254901961\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"Deberta \")\n",
        "print(accuracy_score(target_o + target_s + target_c, deberta_prediction_o + deberta_prediction_s + deberta_prediction_c ))\n",
        "\n",
        "print(\"Deberta FT\")\n",
        "print(accuracy_score(target_o + target_s + target_c, deberta_ft_prediction_o + deberta_ft_prediction_s + deberta_ft_prediction_c ))\n",
        "\n",
        "print(\"Roberta\")\n",
        "print(accuracy_score(target_o + target_s + target_c, roberta_prediction_o + roberta_prediction_s + roberta_prediction_c ))\n",
        "\n",
        "print(\"Roberta Winogrande\")\n",
        "print(accuracy_score(target_o + target_s + target_c, roberta_w_prediction_o + roberta_w_prediction_s + roberta_w_prediction_c ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensemble "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prediction_s = [\n",
        "    deberta_prediction_s,\n",
        "    roberta_w_prediction_s,\n",
        "    deberta_ft_prediction_s\n",
        "]\n",
        "\n",
        "prediction_c = [\n",
        "    deberta_prediction_c,\n",
        "    roberta_w_prediction_c,\n",
        "    deberta_ft_prediction_c\n",
        "]\n",
        "\n",
        "prediction_o = [\n",
        "    deberta_prediction_o,\n",
        "    roberta_w_prediction_o,\n",
        "    deberta_ft_prediction_o\n",
        "]\n",
        "\n",
        "\n",
        "ensemble_pred_o = ensemble_predictions(prediction_o)\n",
        "ensemble_pred_s = ensemble_predictions(prediction_s)\n",
        "ensemble_pred_c = ensemble_predictions(prediction_c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8823529411764706\n",
            "0.8235294117647058\n",
            "0.7058823529411765\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(target_o, ensemble_pred_o))\n",
        "print(accuracy_score(target_s, ensemble_pred_s))\n",
        "print(accuracy_score(target_c, ensemble_pred_c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "o_test_dataset_2 = Brain_Teaser(get_data_lists(o_data))\n",
        "c_test_dataset_2 = Brain_Teaser(get_data_lists(cr_data))\n",
        "s_test_dataset_2 = Brain_Teaser(get_data_lists(sr_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Puzzles\n",
            "1.0\n",
            "Context Puzzles\n",
            "0.893491124260355\n"
          ]
        }
      ],
      "source": [
        "model_deberta_ft_o = AutoModelForMultipleChoice.from_pretrained(\"trained_models/deberta_original\", ignore_mismatched_sizes=True).to(device)\n",
        "deberta_ft_prediction_s, target_s = get_predictions(s_test_dataset_2, model_deberta_ft_o, tokenizer)\n",
        "print(\"Semantic Puzzles\")\n",
        "print(accuracy_score(target_s, deberta_ft_prediction_s))\n",
        "\n",
        "deberta_ft_prediction_c, target_c = get_predictions(c_test_dataset_2, model_deberta_ft_o, tokenizer)\n",
        "print(\"Context Puzzles\")\n",
        "print(accuracy_score(target_c, deberta_ft_prediction_c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Puzzles\n",
            "0.9940828402366864\n",
            "Context Puzzles\n",
            "0.8875739644970414\n"
          ]
        }
      ],
      "source": [
        "model_deberta_ft_s = AutoModelForMultipleChoice.from_pretrained(\"trained_models/deberta_semantic\", ignore_mismatched_sizes=True).to(device)\n",
        "deberta_ft_prediction_o, target_o = get_predictions(o_test_dataset_2, model_deberta_ft_s, tokenizer)\n",
        "print(\"Original Puzzles\")\n",
        "print(accuracy_score(target_o, deberta_ft_prediction_o))\n",
        "\n",
        "deberta_ft_prediction_c, target_c = get_predictions(c_test_dataset_2, model_deberta_ft_s, tokenizer)\n",
        "print(\"Context Puzzles\")\n",
        "print(accuracy_score(target_c, deberta_ft_prediction_c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Puzzles\n",
            "0.863905325443787\n",
            "Semantic Puzzles\n",
            "0.8579881656804734\n"
          ]
        }
      ],
      "source": [
        "model_deberta_ft_c = AutoModelForMultipleChoice.from_pretrained(\"trained_models/deberta_context\", ignore_mismatched_sizes=True).to(device)\n",
        "deberta_ft_prediction_o, target_o = get_predictions(o_test_dataset_2, model_deberta_ft_c, tokenizer)\n",
        "print(\"Original Puzzles\")\n",
        "print(accuracy_score(target_o, deberta_ft_prediction_o))\n",
        "\n",
        "deberta_ft_prediction_s, target_s = get_predictions(s_test_dataset_2, model_deberta_ft_c, tokenizer)\n",
        "print(\"Semantic Puzzles\")\n",
        "print(accuracy_score(target_s, deberta_ft_prediction_s))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
