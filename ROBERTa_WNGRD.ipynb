{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyiUbBz58B39"
      },
      "outputs": [],
      "source": [
        "!pip install datasets==2.14.6\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install --no-cache-dir transformers sentencepiece\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from dataclasses import dataclass\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_scheduler, TrainingArguments, Trainer\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import evaluate\n",
        "import accelerate"
      ],
      "metadata": {
        "id": "iMWTq0UK8DE7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8giCH09x8Et2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"DeepPavlov/roberta-large-winogrande\"\n",
        "# model_name = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train_data = np.load('/content/drive/MyDrive/data/SP-train.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "8gJijVbG8GON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_dataset_type(array):\n",
        "    df = pd.DataFrame(array.tolist())\n",
        "    col = ['id','distractor1','distractor2','distractor(unsure)']\n",
        "    for c in col:\n",
        "      df[c] = df[c].astype(str)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    data = Dataset.from_pandas(df, split = \"train\")\n",
        "    return data\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    first_sentences = [[context] * 4 for context in examples[\"question\"]]\n",
        "    first_sentences = sum(first_sentences, [])\n",
        "    second_sentences = [item for item in examples[\"choice_list\"]]\n",
        "    second_sentences = sum(second_sentences, [])\n",
        "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
        "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
      ],
      "metadata": {
        "id": "NvCvB_7l8Hu0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = convert_to_dataset_type(train_data)\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "print(f\"Training set size: {len(tokenized_train)}\")"
      ],
      "metadata": {
        "id": "rVhTwBxl8Jhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset):\n",
        "    df = dataset.to_pandas()\n",
        "    train_temp, temp_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, shuffle=True)\n",
        "    train_dataset = Dataset.from_pandas(train_temp)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "    dataset_dict = DatasetDict({\n",
        "        \"train\": train_dataset,\n",
        "        \"valid\": val_dataset,\n",
        "        \"test\": test_dataset\n",
        "    })\n",
        "    return dataset_dict\n",
        "\n",
        "my_dataset = split_dataset(tokenized_train)\n",
        "print(\"Training dataset size:\", len(my_dataset['train']))\n",
        "print(\"Validation dataset size:\", len(my_dataset['valid']))\n",
        "print(\"Testing dataset size:\", len(my_dataset['test']))"
      ],
      "metadata": {
        "id": "8DLV3AWb8ME8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "        num_choices = len(features[0][\"input_ids\"])\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return batch"
      ],
      "metadata": {
        "id": "DUiV1JwA8OMo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "HVaUxv2p8P1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_dataset(dataset):\n",
        "    tokenized_dataset = dataset.rename_column(\"label\", \"labels\")\n",
        "    tokenized_dataset = tokenized_dataset.remove_columns(['id', 'question', 'answer', 'distractor1', 'distractor2', 'distractor(unsure)', 'choice_list', 'choice_order'])\n",
        "    tokenized_dataset.set_format(\"torch\")\n",
        "    return tokenized_dataset\n",
        "\n",
        "tokenized_datasets = get_final_dataset(my_dataset)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name, ignore_mismatched_sizes=True)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "SlSkD3Zg8RGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "lr = 5e-5\n",
        "num_epochs = 5\n",
        "\n",
        "num_training_steps = (len(my_dataset[\"train\"]) // batch_size) * num_epochs\n",
        "batches_per_epoch = len(my_dataset[\"train\"]) // batch_size\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "uRHEJngN8S2S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    logging_steps=20,\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=lr,\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    report_to=None,\n",
        "    save_strategy=\"no\"\n",
        "    )"
      ],
      "metadata": {
        "id": "s-E1yjEP8UMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        "    optimizers=(optimizer, lr_scheduler),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "JS-Hex-x8VpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training {model_name}')\n",
        "train_result = trainer.train()"
      ],
      "metadata": {
        "id": "nL78rlor8XQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "ViyxJPnQ8Yon"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(dataset, pred_list=False):\n",
        "    total_answers = 0\n",
        "    correct_answers = 0\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i in dataset:\n",
        "        prompt = i['question'].strip()\n",
        "        candidates = i['choice_list']\n",
        "        true_label_original = i['label']\n",
        "        candidate_1, candidate_2, candidate_3, candidate_4 = candidates[0].strip(), candidates[1].strip(), candidates[2].strip(), candidates[3].strip()\n",
        "\n",
        "        inputs = tokenizer([[prompt, candidate_1], [prompt, candidate_2], [prompt, candidate_3], [prompt, candidate_4]],\n",
        "                           return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "        labels = torch.tensor(true_label_original).unsqueeze(0).to(\"cuda\")  # Batch size 1\n",
        "\n",
        "        # Pass the input through the model to obtain predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_class = logits.argmax().item()\n",
        "\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "        if predicted_class == true_label_original:\n",
        "            correct_answers += 1\n",
        "        total_answers += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_answers / total_answers\n",
        "\n",
        "    # Round accuracy to three decimal places\n",
        "    rounded_accuracy = round(accuracy, 3)\n",
        "    print(\"Accuracy is\", rounded_accuracy)\n",
        "\n",
        "    if pred_list:\n",
        "        return rounded_accuracy, predictions\n",
        "    return rounded_accuracy"
      ],
      "metadata": {
        "id": "bHO6FJOh8Zn5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = evaluate_accuracy(my_dataset['test'])"
      ],
      "metadata": {
        "id": "J2lYv-0P8a5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}