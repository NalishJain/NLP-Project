{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "215e0506c5024299a81ba2c027488735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93aafb82e73d4a9da8d1ae0eadcd6c2b",
              "IPY_MODEL_e422f1acfd2e45279ecb84956c6be6a2",
              "IPY_MODEL_741759a14ce14ce8a63fcb797c4f4b74"
            ],
            "layout": "IPY_MODEL_fba47bb1e7354f2992e21e38999fc4fe"
          }
        },
        "93aafb82e73d4a9da8d1ae0eadcd6c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c25c140b06864bf48b5b2ee6f46d71af",
            "placeholder": "​",
            "style": "IPY_MODEL_0906964c8139498d90a20d2485df16bb",
            "value": "Map: 100%"
          }
        },
        "e422f1acfd2e45279ecb84956c6be6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bafe28db161d4b4e941fae2b309e1319",
            "max": 507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e879d573ca9436ca7043c2d1e29c903",
            "value": 507
          }
        },
        "741759a14ce14ce8a63fcb797c4f4b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0c6fe5df6e4c81b952f3661c705f2b",
            "placeholder": "​",
            "style": "IPY_MODEL_097936840d63467c910afb39093eaca0",
            "value": " 507/507 [00:00&lt;00:00, 567.07 examples/s]"
          }
        },
        "fba47bb1e7354f2992e21e38999fc4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c25c140b06864bf48b5b2ee6f46d71af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0906964c8139498d90a20d2485df16bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bafe28db161d4b4e941fae2b309e1319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e879d573ca9436ca7043c2d1e29c903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d0c6fe5df6e4c81b952f3661c705f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097936840d63467c910afb39093eaca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXvlnZvKpieS"
      },
      "outputs": [],
      "source": [
        "!pip install datasets==2.14.6\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install --no-cache-dir transformers sentencepiece\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from dataclasses import dataclass\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_scheduler, TrainingArguments, Trainer\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import evaluate\n",
        "import accelerate"
      ],
      "metadata": {
        "id": "U1ylTMQLpwuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WxU8SDpkqDUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"FacebookAI/roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train_data = np.load('/content/drive/MyDrive/data/SP-train.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "xpNaJlL5qAU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_dataset_type(array):\n",
        "    df = pd.DataFrame(array.tolist())\n",
        "    col = ['id','distractor1','distractor2','distractor(unsure)']\n",
        "    for c in col:\n",
        "      df[c] = df[c].astype(str)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    data = Dataset.from_pandas(df, split = \"train\")\n",
        "    return data\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    first_sentences = [[context] * 4 for context in examples[\"question\"]]\n",
        "    first_sentences = sum(first_sentences, [])\n",
        "    second_sentences = [item for item in examples[\"choice_list\"]]\n",
        "    second_sentences = sum(second_sentences, [])\n",
        "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
        "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
      ],
      "metadata": {
        "id": "PxD-uk1dr-ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = convert_to_dataset_type(train_data)\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "print(f\"Training set size: {len(tokenized_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "215e0506c5024299a81ba2c027488735",
            "93aafb82e73d4a9da8d1ae0eadcd6c2b",
            "e422f1acfd2e45279ecb84956c6be6a2",
            "741759a14ce14ce8a63fcb797c4f4b74",
            "fba47bb1e7354f2992e21e38999fc4fe",
            "c25c140b06864bf48b5b2ee6f46d71af",
            "0906964c8139498d90a20d2485df16bb",
            "bafe28db161d4b4e941fae2b309e1319",
            "9e879d573ca9436ca7043c2d1e29c903",
            "3d0c6fe5df6e4c81b952f3661c705f2b",
            "097936840d63467c910afb39093eaca0"
          ]
        },
        "id": "9JH-X-fssWzv",
        "outputId": "2d67f8d4-7041-4fab-a2bb-a9fa81a3f2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/507 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "215e0506c5024299a81ba2c027488735"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset):\n",
        "    train_dta, temp_dta = dataset.train_test_split(test_size = 0.2, shuffle=True)\n",
        "    val_dta, test_dta = temp_dta.train_test_split(test_size = 0.5, shuffle=True)\n",
        "    return DatasetDict({\"train\": train_dta,\"test\": test_dta,\"valid\": val_dta})\n",
        "\n",
        "my_dataset = split_dataset(tokenized_train)\n",
        "print(len(my_dataset['train']))\n",
        "print(len(my_dataset['test']))\n",
        "print(len(my_dataset['valid']))"
      ],
      "metadata": {
        "id": "UG75CJsHLJaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "        num_choices = len(features[0][\"input_ids\"])\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return batch"
      ],
      "metadata": {
        "id": "zjOi66mA3lLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "dqiuEWWB4ku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_dataset(dataset):\n",
        "    tokenized_dataset = dataset.rename_column(\"label\", \"labels\")\n",
        "    tokenized_dataset = tokenized_dataset.remove_columns(['id', 'question', 'answer', 'distractor1', 'distractor2', 'distractor(unsure)', 'choice_list', 'choice_order'])\n",
        "    tokenized_dataset.set_format(\"torch\")\n",
        "    return tokenized_dataset\n",
        "\n",
        "tokenized_datasets = get_final_dataset(my_dataset)\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name, ignore_mismatched_sizes=True)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl6d2OYV4sTQ",
        "outputId": "5ce7f5a5-4588-4f53-af47-699531308836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForMultipleChoice(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "lr = 3e-5\n",
        "num_epochs = 3\n",
        "\n",
        "num_training_steps = (len(my_dataset[\"train\"]) // batch_size) * num_epochs\n",
        "batches_per_epoch = len(my_dataset[\"train\"]) // batch_size\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "y6YnpdfR5qGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    logging_steps=20,\n",
        "    logging_strategy=\"steps\",\n",
        "    learning_rate=lr,\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    report_to=None,\n",
        "    save_strategy=\"no\"\n",
        "    )"
      ],
      "metadata": {
        "id": "n0oQrGmc52OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        "    optimizers=(optimizer, lr_scheduler),\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "rU9aVdLg6EQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training {model_name}')\n",
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "dA7-glj26MUt",
        "outputId": "e6d8458a-ceb0-4df8-c9ab-057fb6c67381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training FacebookAI/roberta-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [306/306 05:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.366700</td>\n",
              "      <td>1.364752</td>\n",
              "      <td>0.509804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>0.765653</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.677100</td>\n",
              "      <td>1.178807</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.901200</td>\n",
              "      <td>0.879480</td>\n",
              "      <td>0.627451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.747400</td>\n",
              "      <td>0.653770</td>\n",
              "      <td>0.745098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.359500</td>\n",
              "      <td>0.534894</td>\n",
              "      <td>0.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.307300</td>\n",
              "      <td>0.499781</td>\n",
              "      <td>0.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.351500</td>\n",
              "      <td>0.628856</td>\n",
              "      <td>0.803922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.370400</td>\n",
              "      <td>0.492840</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.316200</td>\n",
              "      <td>0.507408</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.375500</td>\n",
              "      <td>0.667732</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.228100</td>\n",
              "      <td>0.724290</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.218200</td>\n",
              "      <td>0.859567</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.325400</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.118500</td>\n",
              "      <td>0.762947</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_result.metrics\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "aNgUGKdf6N12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(dataset, pred_list=False):\n",
        "    total_answers = 0\n",
        "    correct_answers = 0\n",
        "    predictions = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i in dataset:\n",
        "        prompt = i['question'].strip()\n",
        "        candidates = i['choice_list']\n",
        "        true_label_original = i['label']\n",
        "        candidate_1, candidate_2, candidate_3, candidate_4 = candidates[0].strip(), candidates[1].strip(), candidates[2].strip(), candidates[3].strip()\n",
        "\n",
        "        inputs = tokenizer([[prompt, candidate_1], [prompt, candidate_2], [prompt, candidate_3], [prompt, candidate_4]],\n",
        "                           return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "        labels = torch.tensor(true_label_original).unsqueeze(0).to(\"cuda\")  # Batch size 1\n",
        "\n",
        "        # Pass the input through the model to obtain predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_class = logits.argmax().item()\n",
        "\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "        if predicted_class == true_label_original:\n",
        "            correct_answers += 1\n",
        "        total_answers += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_answers / total_answers\n",
        "\n",
        "    # Round accuracy to three decimal places\n",
        "    rounded_accuracy = round(accuracy, 3)\n",
        "    print(\"Accuracy is\", rounded_accuracy)\n",
        "\n",
        "    if pred_list:\n",
        "        return rounded_accuracy, predictions\n",
        "    return rounded_accuracy"
      ],
      "metadata": {
        "id": "I1kx6Dp96QDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = evaluate_accuracy(my_dataset['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMiMa-b4FiLP",
        "outputId": "1018c8d9-90f8-43c8-d275-777cb40c9d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.882\n"
          ]
        }
      ]
    }
  ]
}